\chapter{Conclusiones}\label{cap.conclusiones}
Tras detallar en profundidad las dos prácticas e implementaciones de las mismas que componen este proyecto, este capítulo se ha reservado para ver hasta qué punto se han logrado los objetivos establecidos, para resumir los conocimientos adquiridos durante su desarrollo y para exponer las posibles mejoras que se pueden introducir en las prácticas, así como trabajos futuros para completar o extender la funcionalidad.

\section{Conclusiones}
El objetivo global de este proyecto era crear dos prácticas nuevas en el entorno docente JdeRobot-Academy. Este objetivo se ha alcanzado con éxito a través de las dos prácticas totalmente funcionales y validadas experimentalmente para comprobar su correcto funcionamiento. Dicho objetivo principal se subdivide en distintos objetivos secundarios, de los cuales a continuación se comentará hasta qué punto se han logrado y cómo. 

El primero de ellos consistía en la creación de la práctica de seguimiento de objetos con una
cámara móvil, la cual  involucraba hardware real. El objetivo se cumplió satisfactoriamente con el desarrollo de la infraestructura y el nodo académico, además de utilizar los \textit{drivers} que permitieron la comunicación entre el nodo y el robot. Hubo que lidiar con ciertos parámetros implícitos en el robot real que muchas veces no son tenidos en cuenta en simulaciones, como la presencia de un \textit{buffer} de mensajes y con el tiempo físico de ejecución de los movimientos del cuello mecánico. Se ha dejado resuelta toda la configuración y se ha añadido un fichero de instrucciones y enunciado que ayudará a futuros usuarios, teniendo así una práctica totalmente funcional y orientada.

El segundo subobjetivo fue la elaboración de práctica de autolocalización de un robot usando
un filtro de partículas y sensor láser. Aunque esta práctica implicaba bastante complejidad gráfica y mucho peso computacional, el objetivo se alcanzó utilizando técnicas de programación multihilo, precomputación y un manejo inteligente de los datos involucrados. En este caso, se preparó un mundo y un modelo de simulación (tanto en aspecto como en funcionalidad), se creó un nodo académico y su infraestructura, y se dejó preparado para incrustar una solución. 

Asociado a ambos subobjetivos hubo que construir sendas soluciones de referencia (una para cada una de las prácticas). No sólo servirían como modelo de posibles soluciones para cada ejercicio, sino que también traería consigo el estudio y asimilación de técnicas de control, procesado, captación y actuación que emplean los robots reales. 

En el caso de la primera práctica, se hizo uso del aprendizaje máquina para entrenar un sistema básico capaz de reconocer caras en posición frontal y otro adicional para reconocer ojos, que juntos permitieron discriminar si una imagen dada contenía caras o no. Estos datos analizados sirvieron para implementar un algoritmo de control gradual, de tal manera que la segmentación de la imagen se traducía en órdenes para los motores de la cámara Sony Evi d100p, la cual seguía al individuo de la imagen. Para hacer la solución algo más completa y robusta, también se incluyó una lógica de gestión en caso de no detectar rostros.

Para la práctica de localización se propuso un algoritmo que utiliza el filtro de partículas. Este proceso involucró varias funciones que solventaban distintas partes del mismo, como el algoritmo de la ruleta para la selección de una partícula a evolucionar, la geometría euclidiana para materializar desplazamientos en las partículas, o la estadística básica para implementar un modelo de observación de partículas. Esta solución se completó con técnicas de mejora de la eficiencia, con soporte para la localización en movimiento y con una serie de ayudas gráficas.

Adicionalmente, queríamos estudiar los requisitos necesarios para construir prácticas que estuviesen disponibles para la mayoría de usuarios. Esto ha sido posible gracias a la plataforma Jupyter, que nos permitió migrar nuestras aplicaciones de escritorio a una versión web, que conservaba la funcionalidad de las originales. Esto abre la puerta para su disponibilidad en distintas plataformas.

Por último, una motivación personal implícita era adquirir el conocimiento y las habilidades necesarias para abordar un problema real de ingeniería, en el cual hubieran involucrados componentes hardware y software. Así, se ha logrado integrar los conceptos que sustentan la infraestructura que hay bajo un proyecto de robótica, las interfaces involucradas, los componentes y, finalmente, la parte visible por el usuario. Por el camino se han adquirido otra serie de competencias útiles y presentes en muchos proyectos, como el modelado de elementos de simulación, el diseño y manejo de interfaces gráficas, el tratamiento de imagen y distintas técnicas de programación.

\section{Trabajos futuros}
El desarrollo de este trabajo ha abierto las puertas a distintas ideas que pueden estudiarse y realizarse en próximos proyectos:

El más destacado es el de alcanzar enteramente unas aplicaciones multiplataforma. El entorno JdeRobot-Academy ha desarrollado recientemente una versión web que permite utilizar el simulador Gazebo de manera remota en consonancia con la plataforma Jupyter. Utilizando un servidor remoto que contenga las prácticas, son ejecutables en cualquier lugar y a través de las plataformas principales (Linux, MacOS, Windows). Aunque aún está en proceso de depuración, más adelante resultaría interesante retocar las prácticas creadas para que estén disponibles a través de dicha herramienta web. 

Otro tema interesante de estudio es la localización basada en visión. Se podría construir una nueva práctica, basada en el nodo académico ya creado (o una versión muy parecida) para abordar el problema de la localización utilizando otro tipo de sensores, como una o varias cámaras. Incluso, podría enriquecerse el modelo empleado para incorporar distintos sensores de diferentes tipos que recogieran información que compusiera una solución más robusta.

Con la primera práctica resultaría interesante montar la cámara en un pequeño robot móvil, y abordar el seguimiento de caras en el espacio 3D. Para ello, sería necesario explorar los tipos de robots móviles, sus motores y sus formas de comunicación, para luego hacerlos compatibles con el nodo e implementar una lógica de seguimiento de personas.

Siempre queda abierta la posibilidad de abordar las mismas prácticas haciendo uso de otro tipo de algoritmos, para así poder realizar una comparación entre ellos y extraer conclusiones acerca de la validez, ventajas y desventajas de cada uno.

Finalmente varios flecos menores también se pueden abordar para mejorar las dos prácticas creadas en este TFG:

\begin{itemize}
	\item La solución propuesta para la práctica Follow Face es capaz de reconocer caras frontales, y en el mejor de los casos rostros girados como mucho 45º desde el eje frontal. Una posible mejora podría ser entrenar el sistema de clasificación con observaciones que incluyan caras rotadas con distintos ángulos, a fin de reconocer todos los casos positivos.
	\item Las comunicaciones en esa práctica emplean dos drivers, uno de los cuales utiliza interfaces ICE. Para la mejora de accesibilidad a la práctica se podría crear uno equivalente que se comunicase a través de mensajes de ROS.
	\item En la práctica de autolocalización, el elevado peso computacional hace que, incluso con las técnicas de optimización empleadas, la eficiencia siga siendo un punto que se puede pulir. Convendría implementar nuevas optimizaciones.
\end{itemize} 