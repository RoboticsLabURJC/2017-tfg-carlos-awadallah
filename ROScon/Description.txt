DESCRIPTION

INTRODUCTION
The JdeRobot-Academy framework for learning robotics is presented on this talk. It is open source, based on ROS middleware and on Gazebo, and uses Python as programming language for the robot logic. It is intended to improve the educational tools available to learn robotics, and aims to bring the field of robotics to the university engineering students in a practical and appealing way, emphasizing in the programming of the robot intelligence more than on its construction.

DESIGN
The framework consists of a set of independent exercises, which are related to successful robotic applications in society (autonomous cars, vacuum cleaners, drones, logistics...). Each exercise is seen as the combination of three layers: physical robot, middleware and application. The lower layer is the physical robot which is aimed to perform some task in a certain environment. The JdeRobot-Academy exercises do not focus on a single specific platform, but use different ones (TurtleBot, cameras, Formula1 car, Roomba, etc.), both simulated in Gazebo or real robots when available. The intermediate layer are the corresponding drivers that give software access to the sensors and actuators of the robot. ROS has been selected for that. In the application layer lies the student's code and algorithms.

Robotic systems are complex. In order to make them easier to the newcomer students an academic ROS node has been created for each JdeRobot-Academy exercise. It (a) provides an easy programming interface for accessing the sensors and actuators of the robot with simple Python methods (HAL API); (b) provides an specific Graphical User Interface for that exercise, which is useful for debugging purposes, and a simple programming interface for it (GUI API); (c) provides a single file template to be filled by the students with their code; (d) includes code that solves auxiliary tasks, for instance an iterative skeleton based on a continuous loop of iterations for reactive behaviors. 

The academic nodes host the student's code which analyzes the sensory data and makes decisions of action, planning if necessary. They can be connected to the real or simulated robot interchangeably just using different configuration files, but without changes on the code itself. 

The use of standard libraries and tools in robotics such as OpenCV, Open Motion Plannig Library or Point Cloud Library is also encouraged in the student solutions.

EXERCISES
The current exercise collection is available at github [https://github.com/JdeRobot/Academy] and the practices can be grouped in four sets [https://jderobot.org/JdeRobot-Academy]: autonomous cars (like [video TeleTaxi] and [video TeleTaxi]), computer vision, drones and mobile robotics. 

Two recent and illustrative exercises will be also detailed in the talk as examples. First, the FollowLine exercise, where a Formula-1 car has to follow the centered red line in a circuit in the shortest time [video]. The student's solution will extract information from the pixels of the on board camera of the robot and will order the corresponding motor commands for the driving wheel and to the accelerator pedal. The student has to learn color filters and ad-hoc processing to extract some information from images, as whether the car is over the red line or not or some measurement of its deviation. A typical solution includes also a case based reactive controller and one or two PID controls. Its graphical interface allows the display of the processing performed on the images.

Second, in the vacuum cleaner exercise the goal is to implement a navigation algorithm to cover the largest area of a known house [video]. The map of the house is provided in a file and the robot is assumed to be accurately located all the time (there is another exercise assuming no localization is provided). The solution of the exercise begins with the planning of the cleaning route, creating a grid on the map to carry out a zigzag path by checking on each pixel if the surrounding cells belong to any obstacle, if they have already been visited, or if they are still cleaning pending. The graphical interface shows the map of the house and the path already travelled by the robot. An automatic evaluator has been also developed for this exercise, it connects with the simulator and provides a score dependending of the size of the cleaned area after 15 minutes.

INSTALLATION
The installation of the framework has been prepared carefully and made very simple on purpose. It only requires the installation of the standard ROS Kinetic packages, the official Gazebo-7 packages, some configuration files and cloning the JdeRobot-Academy github repository.


BALANCE
The JdeRobot-Academy framework has been successfully used on three degree subjects and one master course at Universidad Rey Juan Carlos. It is open to further collaborations, extensions or modifications. Two students of the Google Summer of Code with JdeRobot open project are working on new exercises of JdeRobot-Academy: the Amazon logistics exercise [video] and the use of Open Motion Planning Library in several existing exercises, like autopark of an autonomous car [video]. JdeRobot-Academy will be also used in the PROGRAM-A-ROBOT Competition inside IROS-2018 [enlace a página de IROS Competitions, remarca 'fifth link']. Some demonstration videos of the available practices can be seen in YouTube. 
 
FUTURE LINES
As main future lines, the JdeRobot-Academy team is working on adapting seven existing drone exercises to ROS middleware. They currently run using ICE middleware and Parrot drivers but we are migrating them to MAVros as the middleware for them. Second, an update is planned towards ROS-Melodic and Gazebo 9 in the near future. Third, we are also working on creating a web release of the framework allowing the students to use a WebIDE and program the robots from the browser using Jupyter. 
